"""Add data from an NLP pipeline.
"""

from .recorder import Recorder
from ..tools.myspacy import tokensAndSentences
from ..dataset import modify
from ..core.helpers import console
from ..core.files import initTree


class NLPipeline:
    def __init__(self, app):
        """Enrich a TF dataset with annotations generated by an NLP pipeline.

        Parameters
        ----------
        app: object
            The handle to the original TF dataset, already loaded.
            We assume that the original data resides in the current
            version, which has the string `pre` appended to it,
            e.g. in version `1.3pre`.
            We create a new version of the dataset, with the same number,
            but without the `pre`.
        """
        self.app = app

    def generatePlain(self, takeAways={"note"}, skips={}, write=False):
        """Generates a plain text out of a data source.

        The text is generatad in such a way that out of flow elements are collected
        and put at the end. Examples of such elements are notes.
        Leaving them at their original positions will interfere with sentence detection.

        Parameters
        ----------
        takeAways: set, optional `{"note"}`
            A set of node types whose content will be put in a separate text flow at
            the end of the document.
            It is assumed that for each takeaway element *elem* there is a feature
            `is_`*elem* that has value 1 for each slot in such an element and no value
            otherwise.
        skips: set, optional {}
            A set of features for slots to check. If one of these features hase
            a true-ish value for a slot, that slot will be skipped.
        write: boolean, optional False
            If `True` the result will be written to files in the `_temp` directory of
            the repo, to the files `plain.txt` and `plain.txt.pos`.

        Returns
        -------
        tuple
            The result is a tuple consisting of

            *   *text*: the generated text
            *   *positions*: a list of nodes such that list item *i* contains
                the original slot that corresponds to the character *i* in the
                generated text (counting from zero).
        """
        app = self.app
        api = app.api
        F = api.F
        Fs = api.Fs
        L = api.L
        N = api.N
        slotType = F.otype.slotType

        rec = Recorder(app.api)

        remainingSlots = set(F.otype.s(slotType))

        takeAwaySlots = {}

        for skip in skips:
            test = Fs(skip).v
            remainingSlots -= {s for s in remainingSlots if test(s)}

        for takeAway in takeAways:
            test = Fs(f"is_{takeAway}").v
            takeAwaySlots[takeAway] = {s for s in remainingSlots if test(s)}

        for takeAway in takeAways:
            remainingSlots -= takeAwaySlots[takeAway]
            takeAwaySlots[takeAway] = sorted(takeAwaySlots[takeAway])

        rec.add("BEGIN META.\n\n")

        th = F.otype.s("teiHeader")
        metaNodes = L.d(th[0]) if th else []

        for (n, end) in N.walk(events=True, nodes=metaNodes):
            nType = F.otype.v(n)
            if nType in {"file", "folder", "chapter", "chunk", "word"}:
                continue
            if end is None:  # slot node
                if n in remainingSlots:
                    rec.start(n)
                    rec.add(F.ch.v(n))
                    rec.end(n)
            elif end:  # non slot node ends here
                rec.add(".\n")
            else:  # non slot node starts here
                rec.add(f"{nType}. ")

        rec.add("END META.\n\n")

        metaSlots = {s for s in F.otype.s(slotType) if F.is_meta.v(s)}
        remainingSlots -= metaSlots

        rec.add("BEGIN MAIN.\n\n")

        remainingSlots = sorted(remainingSlots)

        for s in remainingSlots:
            rec.start(s)
            rec.add(F.ch.v(s))
            rec.end(s)

        rec.add("END MAIN.\n\n")

        for takeAway in takeAways:
            rec.add(f"BEGIN {takeAway}s.\n\n")

            for (i, n) in enumerate(F.otype.s(takeAway)):
                slots = L.d(n, otype=slotType)

                rec.add(f"BEGIN {takeAway} {i + 1}.\n\n")

                for s in slots:
                    rec.start(s)
                    rec.add(F.ch.v(s))
                    rec.end(s)

                rec.add(f" .\n\nEND {takeAway} {i + 1}\n\n")

            rec.add(f"END {takeAway}s.\n\n")

        if write:
            repoDir = app.repoLocation
            textPath = f"{repoDir}/_temp/txt/plain.txt"
            rec.write(textPath)
            console(f"Generated text and positions written to {textPath}")

        return (rec.text(), rec.positions(simple=True))

    def ingest(self, positions, stream, tp, features, nFeature=None, skipBlanks=False):
        """Ingests a stream of NLP data and transforms it in nodes and a feature.

        The data is a stream of values associated with a spans of text.

        For each span a node will be created of the given type, and a feature
        of the given name will assign a value to that span.
        The value assigned is by default the value that is present in the data stream,
        but it is possible to specify a method to change the value.

        !!! caution
            The plain text on which the NLP pipeline has run may not correspond
            exactly with the text as defined by the corpus.
            When the plain text was generated, some extra convenience material
            may have been inserted.
            Items in the stream that refer to these pieces of text will be ignored.

            When items refer partly to proper corpus text and partly to convenience text,
            they will be narrowed down to the proper text.

        !!! caution
            The plain text may exhibit another order of material than the proper corpus
            text. For example, notes may have been collected and moved out of the
            main text flow to the end of the text.

            That means that if an item specifies a span in the plain text, it may
            not refer to a single span in the proper text, but to various spans.

            We take care to map all spans in the generated plain text back to *sets*
            of slots in the proper text.

        Parameters
        ----------
        positions: list
            which slot node corresponds to which position in the plain text.

        stream: list of tuple
            The tuples should consist of

            *   *start*: a start number (char pos in the plain text, starting at `0`)
            *   *end*: an end number (char pos in tghe plain text plus one)
            *   *value*: a value for feature assignment

        tp: string
            The type of the nodes that will be generated.

        features: tuple
            The names of the features that will be generated.

        nFeature: string, optional None
            If not None, the name of a feature that will hold the sequence number of
            the element in the data stream, starting at 1.

        skipBlanks: boolean, optional False
            If True, rows whose text component is only white space will be skipped.

        Returns
        -------
        tuple
            We deliver the following pieces of information in a tuple:

            * the last node
            * the mapping of the new nodes to the slots they occupy;
            * the data of the new feature.
        """
        app = self.app
        F = app.api.F

        doN = nFeature is not None
        slots = {}
        featuresData = {feat: {} for feat in features}
        if nFeature is not None:
            featuresData[nFeature] = {}
        node = 0

        itemsOutside = []
        itemsEmpty = []

        console(f"generating {tp}-nodes with features {', '.join(featuresData)} ")

        for (i, (b, e, *vals)) in enumerate(stream):
            mySlots = set()

            for j in range(b, e):
                s = positions[j]
                if s is not None:
                    mySlots.add(s)

            nSlots = len(slots)

            if len(mySlots) == 0:
                if doN:
                    vals.append(i + 1)
                itemsOutside.append((i, b, e, *vals))
                continue

            if skipBlanks and len(vals):
                slotsOrdered = sorted(mySlots)

                start = min(
                    (
                        i
                        for (i, s) in enumerate(slotsOrdered)
                        if F.ch.v(s) not in {" ", "\t", "\n"}
                    ),
                    default=nSlots,
                )
                end = max(
                    (
                        i + 1
                        for (i, s) in enumerate(slotsOrdered)
                        if F.ch.v(s) not in {" ", "\t", "\n"}
                    ),
                    default=0,
                )

                if end <= start:
                    itemsEmpty.append((i, b, e, *vals))
                    continue

                mySlots = slotsOrdered[start:end]

            node += 1
            slots[node] = mySlots
            for (feat, val) in zip(features, vals):
                featuresData[feat][node] = val
            if doN:
                featuresData[nFeature][node] = node

        repFeatures = ", ".join(features + ((nFeature,) if doN else ()))
        console(f"{node} {tp} nodes have values assigned for {repFeatures}")

        tasks = [("Items contained in extra generated text", itemsOutside)]
        if skipBlanks:
            tasks.append(("Items with empty final text", itemsEmpty))
        for (label, items) in tasks:
            nItems = len(items)
            console(f"{nItems:>5}x {label}:")
            for (i, b, e, *vals) in items[0:5]:
                console(f"\t{i} span {b}-{e}: {', '.join(str(v) for v in vals)}")

        return (node, slots, featuresData)

    @staticmethod
    def lingo(*args, **kwargs):
        return tokensAndSentences(*args, **kwargs)

    def ingestTokensAndSentences(
        self,
        positions,
        tokenStream,
        sentenceStream,
        tokenType="token",
        tokenFeatures=("str", "after", None),
        sentenceType="sentence",
        sentenceFeatures=("nsent",),
    ):
        """Ingests a token stream and a sentence stream.


        By default:

        * tokens become nodes of a new type `token`;
        * the texts of a token ends up in the feature `str`;
        * if there is a space after a token, it ends up in the feature `after`;
        * sentences become nodes of a new type `sentence`;
        * the sentence number ends up in the feature `nsent`.

        But this function can also be adapted to token and sentence streams that
        have additional names and values, see below.

        The streams of tokens and sentences may contain more fields.
        In the parameters `tokenFeatures` and `sentenceFeatures` you may pass the
        feature names for the data in those fields.

        When the streams are read, for each feature name in the `tokenFeatures`
        (resp. `sentenceFeatures`) the corresponding field in the stream will be
        read, and the value found there will be assigned to that feature.

        If there are more fields in the stream than there are declared in the
        `tokenFeatures` (resp. `sentenceFeatures`) parameter, these extra fields will
        be ignored.

        The last feature name in these parameters is special.
        If it is None, it will be ignored.
        Otherwise, an extra feature with that name will be created, and it will be
        filled with the node numbers of the newly generated nodes.

        !!! hint "Look at the defaults"
            The default `tokenFeatures=("str", "after", None)` specifies that two
            fields from the tokenstream will be read, and those values will be assigned
            to features `str` and `after`.
            There will be no field with the node itself in it.

            The default `sentenceFeatures=("nsent",)` specifies that no field from the
            tokenstream will be read, but that there will be a feature `nsent` that
            has the node of each sentence as value.

        Parameters
        ----------
        tokenStream: list
            The list of tokens as delivered by the NLP pipe.
        sentenceStream: list
            The list of sentences as delivered by the NLP pipe.
        tokenType: string, optional str
            The node type for the tokens
        tokenFeatures: tuple, optional ("str", "after", "")
            The names of the features that the token stream contains.
        sentenceType: string, optional str
            The node type for the sentences
        sentenceFeatures: tuple, optional ("nsent",)
            The names of the features that the sentence stream contains.

        Returns
        -------
        string
            The new version number of the data that contains the tokens and sentences.
        """
        app = self.app
        slotLinks = {tokenType: {}, sentenceType: {}}
        features = {}
        for feat in tokenFeatures:
            if feat is not None:
                features[feat] = {}
        for feat in sentenceFeatures:
            if feat is not None:
                features[feat] = {}
        lastNode = {tokenType: 0, sentenceType: 0}

        for (data, tp, feats, skipBlanks) in (
            (tokenStream, tokenType, tokenFeatures, False),
            (sentenceStream, sentenceType, sentenceFeatures, True),
        ):
            realFeats = feats[0:-1]
            nFeat = feats[-1]
            (node, slots, featuresData) = self.ingest(
                positions,
                data,
                tp,
                realFeats,
                nFeature=nFeat,
                skipBlanks=skipBlanks,
            )
            lastNode[tp] = node
            slotLinks[tp] = slots
            for (feat, featData) in featuresData.items():
                features[feat] = featData

        repoDir = app.repoLocation
        versionPre = app.version
        version = versionPre.removesuffix("pre")
        origTf = f"{repoDir}/tf/{versionPre}"
        newTf = f"{repoDir}/tf/{version}"
        initTree(newTf, fresh=True, gentle=False)

        modify(
            origTf,
            newTf,
            addTypes=dict(
                token=dict(
                    nodeFrom=1,
                    nodeTo=lastNode[tokenType],
                    nodeSlots=slotLinks[tokenType],
                    nodeFeatures={
                        feat: features[feat]
                        for feat in tokenFeatures
                        if feat is not None
                    },
                ),
                sentence=dict(
                    nodeFrom=1,
                    nodeTo=lastNode[sentenceType],
                    nodeSlots=slotLinks[sentenceType],
                    nodeFeatures={
                        feat: features[feat]
                        for feat in sentenceFeatures
                        if feat is not None
                    },
                ),
            ),
            deleteTypes=("word",),
            featureMeta=dict(
                nsent=dict(
                    valueType="int",
                    description="number of sentence in corpus",
                ),
                otext={
                    "fmt:text-orig-full": "{"
                    + tokenFeatures[0]
                    + "}{"
                    + tokenFeatures[1]
                    + "}"
                },
            ),
            replaceSlotType=tokenType,
        )
        return version


def addTokensSentences(app, write=False):
    """Creates a new version in a TF dataset with token and sentence nodes.

    Parameters
    ----------
    app: object
        The handle to the original TF dataset.
        We assume that the original data resides in the current
        version, which has the string `pre` appended to it,
        e.g. in version `1.3pre`.
        We create a new version of the dataset, with the same number,
        but without the `pre`.
    write: boolean, optional False
        If `True` the result will be written to files in the `_temp` directory of
        the repo, to the files `plain.txt` and `plain.txt.pos`.

    """
    NLP = NLPipeline(app)
    app.indent(reset=True)
    app.info("Generating a plain text with positions ...")

    (text, positions) = NLP.generatePlain(write=write)

    app.info("Getting tokens and sentences from Spacy ...")

    (tokens, sentences) = NLP.lingo(text)

    app.info("Ingesting tokens and sentences into the dataset (Spacy) ...")

    newVersion = NLP.ingestTokensAndSentences(positions, tokens, sentences)
    app.info(f"Enriched data is available in version {newVersion}")
    app.info(
        "You may need to adapt the config.yaml and app.py of this TF app", tm=False
    )
    app.info(
        "And the documententation of the transcription may need an update", tm=False
    )
    app.info(
        "If you have generated the orginal app by means of `tf.convert.tei`", tm=False
    )
    app.info("you can run `python tfFromTei.py appt", tm=False)
